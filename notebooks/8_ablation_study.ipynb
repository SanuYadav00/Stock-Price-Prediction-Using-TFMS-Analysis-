{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edefd836-a53a-48ab-957b-41cdf5317778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import Sequential, clone_model\n",
    "\n",
    "\n",
    "import joblib\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, clone\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from tensorflow.keras.models import Sequential, clone_model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import model_from_json\n",
    "import json\n",
    "\n",
    "# Updated KerasRegressorWrapper\n",
    "from tensorflow.keras.models import save_model, load_model\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "TICKERS = [\"AAPL\", \"JPM\", \"AMZN\", \"PFE\", \"XOM\"]\n",
    "N_FOLDS = 5\n",
    "\n",
    "# Set correct technical, fundamental, sentiment columns here as per your data\n",
    "TECHNICAL_FEATURES = ['RSI_14', 'SMA_20', 'Volume']\n",
    "FUNDAMENTAL_FEATURES = ['debt_to_equity']\n",
    "SENTIMENT_FEATURES = ['sentiment_3day_ma']\n",
    "\n",
    "TARGET_COL = 'target_5day_return'\n",
    "LOOKBACK = 60\n",
    "\n",
    "# Import your model functions (adjust import as needed)\n",
    "# from your_module import train_technical_model, train_fundamental_model, train_sentiment_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4652c80b-11f0-4d14-a110-26521ba9a992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_technical_model(input_shape):\n",
    "    \"\"\"Model builder function that returns a fresh compiled model\"\"\"\n",
    "    model = Sequential([\n",
    "        Input(shape=input_shape),\n",
    "        LSTM(64,\n",
    "             activation='tanh',\n",
    "             recurrent_activation='sigmoid',\n",
    "             kernel_initializer='glorot_uniform',\n",
    "             recurrent_initializer='orthogonal',\n",
    "             kernel_constraint=MaxNorm(3),\n",
    "             recurrent_constraint=MaxNorm(3)),\n",
    "        Dropout(0.2),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_technical_model(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Train LSTM model with proper initialization and gradient control\"\"\"\n",
    "    # Normalize targets\n",
    "    y_mean, y_std = y_train.mean(), y_train.std()\n",
    "    y_train_norm = (y_train - y_mean) / y_std\n",
    "    y_test_norm = (y_test - y_mean) / y_std\n",
    "    \n",
    "    # Build and compile model\n",
    "    model = build_technical_model((X_train.shape[1], X_train.shape[2]))\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001, clipvalue=1.0),\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    # Train with callbacks\n",
    "    history = model.fit(\n",
    "        X_train, y_train_norm,\n",
    "        validation_data=(X_test, y_test_norm),\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        callbacks=[\n",
    "            EarlyStopping(patience=10, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(factor=0.5, patience=5)\n",
    "        ],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Store normalization parameters\n",
    "    model.y_mean = y_mean\n",
    "    model.y_std = y_std\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def train_fundamental_model(X_train, y_train):\n",
    "    \"\"\"XGBoost model for fundamentals\"\"\"\n",
    "    model = XGBRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=3,\n",
    "        learning_rate=0.1,\n",
    "        objective='reg:squarederror'\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76392a10-e7ea-42b1-a793-cf34b10d96fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def direction_accuracy(y_true, y_pred):\n",
    "    return np.mean(np.sign(y_true) == np.sign(y_pred))\n",
    "\n",
    "def sharpe_ratio(returns, risk_free_rate=0):\n",
    "    excess = returns - risk_free_rate\n",
    "    if np.std(excess) == 0:\n",
    "        return 0.0\n",
    "    return np.mean(excess) / (np.std(excess) + 1e-9) * np.sqrt(252)\n",
    "\n",
    "# Rolling window creator for LSTM\n",
    "def create_rolling_sequences(df, features, target_col, lookback=60):\n",
    "    n_samples = len(df) - lookback + 1\n",
    "    X = np.zeros((n_samples, lookback, len(features)))\n",
    "    y = np.zeros(n_samples)\n",
    "    for i in range(n_samples):\n",
    "        X[i] = df[features].iloc[i:i+lookback].values\n",
    "        y[i] = df[target_col].iloc[i+lookback-1]\n",
    "    return X, y\n",
    "\n",
    "# Diebold-Mariano test\n",
    "def diebold_mariano_test(e1, e2, h=1):\n",
    "    # e1/e2: arrays of forecast errors (e.g., y_true - y_pred)\n",
    "    # h: forecast horizon, 1 for one-step ahead\n",
    "    from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "    import scipy.stats as stats\n",
    "    d = np.abs(e1) - np.abs(e2)\n",
    "    mean_d = np.mean(d)\n",
    "    n = len(d)\n",
    "    var_d = np.var(d, ddof=1)\n",
    "    # Approximate DM statistic\n",
    "    dm_stat = mean_d / (np.sqrt(var_d / n + 1e-9))\n",
    "    p_value = 2 * (1 - stats.norm.cdf(np.abs(dm_stat)))\n",
    "    return dm_stat, p_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a569707-c746-4710-b28c-b2c3bd1d9438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== AAPL ==========\n",
      "Epoch 1/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 178ms/step - loss: 0.7866 - mae: 0.6850 - val_loss: 1.2122 - val_mae: 0.8527 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.7228 - mae: 0.6434 - val_loss: 1.0788 - val_mae: 0.7792 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.6737 - mae: 0.6010 - val_loss: 1.0396 - val_mae: 0.7610 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.5688 - mae: 0.5759 - val_loss: 1.0435 - val_mae: 0.7683 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.5847 - mae: 0.5836 - val_loss: 1.0504 - val_mae: 0.7733 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.5818 - mae: 0.5867 - val_loss: 1.0488 - val_mae: 0.7698 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.5507 - mae: 0.5874 - val_loss: 1.0506 - val_mae: 0.7701 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 214ms/step - loss: 0.5087 - mae: 0.5491 - val_loss: 1.0469 - val_mae: 0.7669 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.4999 - mae: 0.5482 - val_loss: 1.0456 - val_mae: 0.7659 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.5669 - mae: 0.5789 - val_loss: 1.0419 - val_mae: 0.7638 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.6101 - mae: 0.6065 - val_loss: 1.0424 - val_mae: 0.7638 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.5884 - mae: 0.6020 - val_loss: 1.0503 - val_mae: 0.7700 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.5543 - mae: 0.5667 - val_loss: 1.0649 - val_mae: 0.7776 - learning_rate: 5.0000e-04\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 1/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 101ms/step - loss: 0.9235 - mae: 0.7471 - val_loss: 0.3255 - val_mae: 0.4434 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.6092 - mae: 0.5712 - val_loss: 0.3062 - val_mae: 0.4382 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 0.5557 - mae: 0.5650 - val_loss: 0.3038 - val_mae: 0.4352 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.5998 - mae: 0.5885 - val_loss: 0.3278 - val_mae: 0.4561 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.5695 - mae: 0.5826 - val_loss: 0.3400 - val_mae: 0.4689 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.5496 - mae: 0.5686 - val_loss: 0.3827 - val_mae: 0.5081 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.6047 - mae: 0.5847 - val_loss: 0.3528 - val_mae: 0.4797 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.5156 - mae: 0.5551 - val_loss: 0.3851 - val_mae: 0.5052 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.5132 - mae: 0.5565 - val_loss: 0.3726 - val_mae: 0.4967 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 122ms/step - loss: 0.5001 - mae: 0.5312 - val_loss: 0.3508 - val_mae: 0.4779 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 105ms/step - loss: 0.5368 - mae: 0.5491 - val_loss: 0.3952 - val_mae: 0.5141 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - loss: 0.4662 - mae: 0.5298 - val_loss: 0.3912 - val_mae: 0.5116 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - loss: 0.4508 - mae: 0.5233 - val_loss: 0.4008 - val_mae: 0.5202 - learning_rate: 5.0000e-04\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "Epoch 1/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 70ms/step - loss: 0.7359 - mae: 0.6619 - val_loss: 0.5057 - val_mae: 0.5557 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.5834 - mae: 0.5976 - val_loss: 0.4719 - val_mae: 0.5280 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.6401 - mae: 0.6217 - val_loss: 0.4812 - val_mae: 0.5322 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 0.5850 - mae: 0.5845 - val_loss: 0.4714 - val_mae: 0.5235 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 0.5953 - mae: 0.5911 - val_loss: 0.4706 - val_mae: 0.5233 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 0.5740 - mae: 0.5900 - val_loss: 0.5088 - val_mae: 0.5573 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 0.5664 - mae: 0.5917 - val_loss: 0.4809 - val_mae: 0.5339 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 0.5372 - mae: 0.5743 - val_loss: 0.4685 - val_mae: 0.5213 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 0.5003 - mae: 0.5534 - val_loss: 0.4799 - val_mae: 0.5289 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 0.5775 - mae: 0.5791 - val_loss: 0.5104 - val_mae: 0.5579 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 0.4992 - mae: 0.5339 - val_loss: 0.4857 - val_mae: 0.5261 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 0.5026 - mae: 0.5471 - val_loss: 0.5207 - val_mae: 0.5637 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.4713 - mae: 0.5432 - val_loss: 0.5217 - val_mae: 0.5568 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 0.4383 - mae: 0.5148 - val_loss: 0.5553 - val_mae: 0.5849 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 0.4918 - mae: 0.5438 - val_loss: 0.5187 - val_mae: 0.5395 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - loss: 0.4199 - mae: 0.4903 - val_loss: 0.5445 - val_mae: 0.5670 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.4256 - mae: 0.5073 - val_loss: 0.5538 - val_mae: 0.5753 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - loss: 0.4221 - mae: 0.5057 - val_loss: 0.5696 - val_mae: 0.5815 - learning_rate: 5.0000e-04\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Epoch 1/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 118ms/step - loss: 0.7518 - mae: 0.6699 - val_loss: 1.3612 - val_mae: 0.8210 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - loss: 0.5893 - mae: 0.5962 - val_loss: 1.3916 - val_mae: 0.8304 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 0.6047 - mae: 0.6005 - val_loss: 1.3171 - val_mae: 0.7861 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - loss: 0.6001 - mae: 0.5914 - val_loss: 1.3248 - val_mae: 0.7985 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 0.5538 - mae: 0.5834 - val_loss: 1.3494 - val_mae: 0.8130 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - loss: 0.5421 - mae: 0.5672 - val_loss: 1.3217 - val_mae: 0.7978 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.5555 - mae: 0.5686 - val_loss: 1.3195 - val_mae: 0.7838 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.5525 - mae: 0.5666 - val_loss: 1.2753 - val_mae: 0.7652 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 0.4947 - mae: 0.5494 - val_loss: 1.3082 - val_mae: 0.7734 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.4670 - mae: 0.5248 - val_loss: 1.2871 - val_mae: 0.7779 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.4400 - mae: 0.5238 - val_loss: 1.2467 - val_mae: 0.7620 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.4409 - mae: 0.5134 - val_loss: 1.2289 - val_mae: 0.7511 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.4214 - mae: 0.5093 - val_loss: 1.2400 - val_mae: 0.7869 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - loss: 0.4274 - mae: 0.5092 - val_loss: 1.1945 - val_mae: 0.7472 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.3678 - mae: 0.4766 - val_loss: 1.2173 - val_mae: 0.7779 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.3686 - mae: 0.4806 - val_loss: 1.1661 - val_mae: 0.7655 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.3213 - mae: 0.4476 - val_loss: 1.1858 - val_mae: 0.7636 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.2982 - mae: 0.4319 - val_loss: 1.1852 - val_mae: 0.7859 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - loss: 0.3006 - mae: 0.4322 - val_loss: 1.2176 - val_mae: 0.8236 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.2996 - mae: 0.4266 - val_loss: 1.1236 - val_mae: 0.7810 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.2869 - mae: 0.4180 - val_loss: 1.1659 - val_mae: 0.7963 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.2759 - mae: 0.4078 - val_loss: 1.1830 - val_mae: 0.8125 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 0.2570 - mae: 0.3997 - val_loss: 1.1755 - val_mae: 0.8128 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.2414 - mae: 0.3888 - val_loss: 1.2505 - val_mae: 0.8585 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - loss: 0.2426 - mae: 0.3730 - val_loss: 1.1614 - val_mae: 0.8058 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.2262 - mae: 0.3718 - val_loss: 1.1777 - val_mae: 0.8131 - learning_rate: 5.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - loss: 0.2332 - mae: 0.3791 - val_loss: 1.1490 - val_mae: 0.8049 - learning_rate: 5.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.2180 - mae: 0.3647 - val_loss: 1.1637 - val_mae: 0.7925 - learning_rate: 5.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - loss: 0.2468 - mae: 0.3814 - val_loss: 1.1514 - val_mae: 0.7972 - learning_rate: 5.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.2178 - mae: 0.3591 - val_loss: 1.2087 - val_mae: 0.8289 - learning_rate: 5.0000e-04\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "========== JPM ==========\n",
      "Epoch 1/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 186ms/step - loss: 0.8398 - mae: 0.6993 - val_loss: 1.6376 - val_mae: 0.9744 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.7088 - mae: 0.6134 - val_loss: 1.6444 - val_mae: 0.9744 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.6983 - mae: 0.6197 - val_loss: 1.6311 - val_mae: 0.9755 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.6397 - mae: 0.6149 - val_loss: 1.6720 - val_mae: 0.9905 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.5271 - mae: 0.5431 - val_loss: 1.7900 - val_mae: 1.0287 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.5454 - mae: 0.5523 - val_loss: 1.6939 - val_mae: 0.9987 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.5658 - mae: 0.5572 - val_loss: 1.5020 - val_mae: 0.9305 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.5037 - mae: 0.5373 - val_loss: 1.6808 - val_mae: 0.9863 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.4511 - mae: 0.5325 - val_loss: 1.4259 - val_mae: 0.9047 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.4834 - mae: 0.5375 - val_loss: 1.3098 - val_mae: 0.8574 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.5234 - mae: 0.5534 - val_loss: 1.3123 - val_mae: 0.8663 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.4494 - mae: 0.5201 - val_loss: 1.3322 - val_mae: 0.8658 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.5070 - mae: 0.5371 - val_loss: 1.3218 - val_mae: 0.8685 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.4385 - mae: 0.5041 - val_loss: 1.3321 - val_mae: 0.8790 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.4660 - mae: 0.5223 - val_loss: 1.3275 - val_mae: 0.8765 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.4671 - mae: 0.5300 - val_loss: 1.3271 - val_mae: 0.8697 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.4520 - mae: 0.5046 - val_loss: 1.3406 - val_mae: 0.8709 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.4432 - mae: 0.5201 - val_loss: 1.3450 - val_mae: 0.8819 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.4515 - mae: 0.5280 - val_loss: 1.3645 - val_mae: 0.8935 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.4340 - mae: 0.5073 - val_loss: 1.3554 - val_mae: 0.8883 - learning_rate: 5.0000e-04\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Epoch 1/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 262ms/step - loss: 0.8512 - mae: 0.7005 - val_loss: 0.3481 - val_mae: 0.4536 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 105ms/step - loss: 0.5610 - mae: 0.5549 - val_loss: 0.3776 - val_mae: 0.4783 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.5036 - mae: 0.5370 - val_loss: 0.3535 - val_mae: 0.4637 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.5332 - mae: 0.5706 - val_loss: 0.3611 - val_mae: 0.4770 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.4937 - mae: 0.5355 - val_loss: 0.3469 - val_mae: 0.4727 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.5094 - mae: 0.5448 - val_loss: 0.3372 - val_mae: 0.4662 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - loss: 0.5474 - mae: 0.5627 - val_loss: 0.3492 - val_mae: 0.4766 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - loss: 0.5328 - mae: 0.5593 - val_loss: 0.3434 - val_mae: 0.4713 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - loss: 0.4996 - mae: 0.5368 - val_loss: 0.3530 - val_mae: 0.4804 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.5068 - mae: 0.5504 - val_loss: 0.3686 - val_mae: 0.4890 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 103ms/step - loss: 0.4581 - mae: 0.5365 - val_loss: 0.3663 - val_mae: 0.4896 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.4503 - mae: 0.5010 - val_loss: 0.3938 - val_mae: 0.5112 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.4131 - mae: 0.4973 - val_loss: 0.4141 - val_mae: 0.5257 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.4830 - mae: 0.5303 - val_loss: 0.4241 - val_mae: 0.5294 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.4330 - mae: 0.5019 - val_loss: 0.4195 - val_mae: 0.5293 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 154ms/step - loss: 0.4224 - mae: 0.4980 - val_loss: 0.4253 - val_mae: 0.5334 - learning_rate: 5.0000e-04\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 207ms/step\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n",
      "Epoch 1/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 129ms/step - loss: 1.0776 - mae: 0.7865 - val_loss: 1.2762 - val_mae: 0.8055 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.6657 - mae: 0.6053 - val_loss: 1.0092 - val_mae: 0.7228 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.6490 - mae: 0.5987 - val_loss: 0.9853 - val_mae: 0.7149 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 0.5720 - mae: 0.5796 - val_loss: 0.9427 - val_mae: 0.7043 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - loss: 0.5282 - mae: 0.5504 - val_loss: 0.9831 - val_mae: 0.7117 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.5662 - mae: 0.5700 - val_loss: 0.9607 - val_mae: 0.7098 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 0.5401 - mae: 0.5602 - val_loss: 0.9952 - val_mae: 0.7155 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.5253 - mae: 0.5476 - val_loss: 0.9943 - val_mae: 0.7153 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 0.5186 - mae: 0.5575 - val_loss: 0.9896 - val_mae: 0.7148 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.5263 - mae: 0.5489 - val_loss: 1.0348 - val_mae: 0.7277 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.5110 - mae: 0.5463 - val_loss: 1.0218 - val_mae: 0.7243 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.4530 - mae: 0.5186 - val_loss: 1.0013 - val_mae: 0.7186 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - loss: 0.4649 - mae: 0.5247 - val_loss: 1.0050 - val_mae: 0.7202 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.4239 - mae: 0.5096 - val_loss: 1.0320 - val_mae: 0.7273 - learning_rate: 5.0000e-04\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step\n",
      "Epoch 1/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 76ms/step - loss: 0.6315 - mae: 0.6082 - val_loss: 0.8276 - val_mae: 0.6499 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - loss: 0.5945 - mae: 0.5961 - val_loss: 0.9581 - val_mae: 0.7251 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - loss: 0.6450 - mae: 0.6261 - val_loss: 0.9278 - val_mae: 0.7168 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - loss: 0.5784 - mae: 0.5898 - val_loss: 0.8782 - val_mae: 0.6892 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 0.5505 - mae: 0.5770 - val_loss: 0.9128 - val_mae: 0.7125 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.5132 - mae: 0.5521 - val_loss: 0.8750 - val_mae: 0.6971 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.5747 - mae: 0.5864 - val_loss: 1.0464 - val_mae: 0.7941 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - loss: 0.5307 - mae: 0.5563 - val_loss: 0.9544 - val_mae: 0.7460 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - loss: 0.5146 - mae: 0.5466 - val_loss: 1.0106 - val_mae: 0.7796 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.4956 - mae: 0.5416 - val_loss: 1.0187 - val_mae: 0.7919 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.5034 - mae: 0.5535 - val_loss: 0.9490 - val_mae: 0.7568 - learning_rate: 5.0000e-04\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
      "========== AMZN ==========\n",
      "Epoch 1/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 272ms/step - loss: 0.9837 - mae: 0.7603 - val_loss: 2.9013 - val_mae: 1.2762 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.8864 - mae: 0.7075 - val_loss: 2.7064 - val_mae: 1.2202 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.7425 - mae: 0.6638 - val_loss: 2.6134 - val_mae: 1.2040 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.6045 - mae: 0.6140 - val_loss: 2.5813 - val_mae: 1.1991 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.6223 - mae: 0.6133 - val_loss: 2.6083 - val_mae: 1.2201 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.5542 - mae: 0.6011 - val_loss: 2.5562 - val_mae: 1.2167 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.5406 - mae: 0.5854 - val_loss: 2.4239 - val_mae: 1.1837 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.6264 - mae: 0.6355 - val_loss: 2.3900 - val_mae: 1.1937 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.6401 - mae: 0.6165 - val_loss: 2.5502 - val_mae: 1.2540 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.6453 - mae: 0.6278 - val_loss: 2.3632 - val_mae: 1.2090 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.5911 - mae: 0.6184 - val_loss: 2.4821 - val_mae: 1.2532 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.4909 - mae: 0.5580 - val_loss: 3.2102 - val_mae: 1.4219 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.5585 - mae: 0.5843 - val_loss: 3.2539 - val_mae: 1.4341 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.5078 - mae: 0.5539 - val_loss: 2.8509 - val_mae: 1.3521 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.5296 - mae: 0.5642 - val_loss: 2.6467 - val_mae: 1.3169 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.4673 - mae: 0.5365 - val_loss: 2.6611 - val_mae: 1.3210 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.5121 - mae: 0.5661 - val_loss: 2.7474 - val_mae: 1.3410 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.4706 - mae: 0.5492 - val_loss: 2.9106 - val_mae: 1.3727 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.5083 - mae: 0.5531 - val_loss: 2.9945 - val_mae: 1.3896 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.4762 - mae: 0.5418 - val_loss: 2.9540 - val_mae: 1.3868 - learning_rate: 5.0000e-04\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 1/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 114ms/step - loss: 0.8348 - mae: 0.6618 - val_loss: 0.2958 - val_mae: 0.4243 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 0.6831 - mae: 0.6267 - val_loss: 0.2978 - val_mae: 0.4350 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.6381 - mae: 0.6055 - val_loss: 0.3028 - val_mae: 0.4358 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.7110 - mae: 0.6386 - val_loss: 0.2999 - val_mae: 0.4351 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.5849 - mae: 0.5786 - val_loss: 0.3022 - val_mae: 0.4350 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.6659 - mae: 0.6303 - val_loss: 0.3034 - val_mae: 0.4380 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.6184 - mae: 0.6155 - val_loss: 0.3074 - val_mae: 0.4404 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 0.6692 - mae: 0.6295 - val_loss: 0.3142 - val_mae: 0.4464 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 0.6960 - mae: 0.6457 - val_loss: 0.3277 - val_mae: 0.4567 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.5835 - mae: 0.5862 - val_loss: 0.3183 - val_mae: 0.4497 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 0.5948 - mae: 0.6033 - val_loss: 0.3112 - val_mae: 0.4416 - learning_rate: 5.0000e-04\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Epoch 1/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - loss: 0.9176 - mae: 0.7108 - val_loss: 0.3381 - val_mae: 0.4637 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 0.6778 - mae: 0.6077 - val_loss: 0.3048 - val_mae: 0.4456 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 0.6932 - mae: 0.6213 - val_loss: 0.3115 - val_mae: 0.4482 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 0.5742 - mae: 0.5685 - val_loss: 0.3172 - val_mae: 0.4519 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 0.6475 - mae: 0.6061 - val_loss: 0.3374 - val_mae: 0.4632 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.6686 - mae: 0.6198 - val_loss: 0.3430 - val_mae: 0.4665 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 0.5625 - mae: 0.5617 - val_loss: 0.3318 - val_mae: 0.4620 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 0.5789 - mae: 0.5686 - val_loss: 0.3496 - val_mae: 0.4708 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 0.5959 - mae: 0.5742 - val_loss: 0.3546 - val_mae: 0.4732 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 0.5267 - mae: 0.5416 - val_loss: 0.3841 - val_mae: 0.4891 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 0.5943 - mae: 0.5794 - val_loss: 0.3677 - val_mae: 0.4808 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.5179 - mae: 0.5468 - val_loss: 0.3820 - val_mae: 0.4885 - learning_rate: 5.0000e-04\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Epoch 1/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - loss: 0.7392 - mae: 0.6268 - val_loss: 0.4612 - val_mae: 0.5040 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.6935 - mae: 0.6214 - val_loss: 0.5478 - val_mae: 0.5874 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.6937 - mae: 0.6165 - val_loss: 0.4728 - val_mae: 0.5151 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.6321 - mae: 0.5885 - val_loss: 0.5053 - val_mae: 0.5520 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.6177 - mae: 0.5877 - val_loss: 0.4853 - val_mae: 0.5296 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.5879 - mae: 0.5761 - val_loss: 0.5653 - val_mae: 0.5997 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.6215 - mae: 0.5859 - val_loss: 0.4989 - val_mae: 0.5427 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.5452 - mae: 0.5665 - val_loss: 0.5027 - val_mae: 0.5479 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.6347 - mae: 0.5998 - val_loss: 0.5088 - val_mae: 0.5477 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.5770 - mae: 0.5690 - val_loss: 0.5083 - val_mae: 0.5469 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.5540 - mae: 0.5708 - val_loss: 0.5013 - val_mae: 0.5389 - learning_rate: 5.0000e-04\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
      "========== PFE ==========\n",
      "Epoch 1/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 181ms/step - loss: 0.8792 - mae: 0.7013 - val_loss: 0.7001 - val_mae: 0.6608 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.6433 - mae: 0.5417 - val_loss: 0.6316 - val_mae: 0.6340 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.5633 - mae: 0.5556 - val_loss: 0.6564 - val_mae: 0.6496 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.5725 - mae: 0.5631 - val_loss: 0.6004 - val_mae: 0.6137 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.5704 - mae: 0.5419 - val_loss: 0.6094 - val_mae: 0.6216 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.4743 - mae: 0.5153 - val_loss: 0.6427 - val_mae: 0.6432 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.5088 - mae: 0.5326 - val_loss: 0.6777 - val_mae: 0.6625 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.4322 - mae: 0.4941 - val_loss: 0.6858 - val_mae: 0.6713 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.5675 - mae: 0.5590 - val_loss: 0.6602 - val_mae: 0.6602 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.4783 - mae: 0.5168 - val_loss: 0.7445 - val_mae: 0.6986 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.4855 - mae: 0.5311 - val_loss: 0.8426 - val_mae: 0.7411 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 0.5006 - mae: 0.5476 - val_loss: 0.7991 - val_mae: 0.7295 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.4406 - mae: 0.5017 - val_loss: 0.7560 - val_mae: 0.7114 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.4422 - mae: 0.5026 - val_loss: 0.7293 - val_mae: 0.7001 - learning_rate: 5.0000e-04\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Epoch 1/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 106ms/step - loss: 0.8434 - mae: 0.7056 - val_loss: 0.7157 - val_mae: 0.6540 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 0.6293 - mae: 0.6018 - val_loss: 0.5531 - val_mae: 0.5907 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 0.5222 - mae: 0.5588 - val_loss: 0.5619 - val_mae: 0.5887 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.5406 - mae: 0.5605 - val_loss: 0.5789 - val_mae: 0.5919 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 0.5307 - mae: 0.5647 - val_loss: 0.5821 - val_mae: 0.5926 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.5181 - mae: 0.5492 - val_loss: 0.5831 - val_mae: 0.5951 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 0.4935 - mae: 0.5415 - val_loss: 0.6068 - val_mae: 0.6018 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.5004 - mae: 0.5501 - val_loss: 0.6020 - val_mae: 0.6023 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 0.5067 - mae: 0.5478 - val_loss: 0.6195 - val_mae: 0.6067 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 0.5175 - mae: 0.5539 - val_loss: 0.6207 - val_mae: 0.6079 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.5271 - mae: 0.5607 - val_loss: 0.6234 - val_mae: 0.6091 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 0.5123 - mae: 0.5544 - val_loss: 0.6415 - val_mae: 0.6138 - learning_rate: 5.0000e-04\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Epoch 1/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 93ms/step - loss: 0.7534 - mae: 0.6634 - val_loss: 0.5784 - val_mae: 0.5888 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 0.6042 - mae: 0.5802 - val_loss: 0.5998 - val_mae: 0.6039 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.5748 - mae: 0.5922 - val_loss: 0.6636 - val_mae: 0.6239 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.5863 - mae: 0.5854 - val_loss: 0.6021 - val_mae: 0.6002 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.5256 - mae: 0.5608 - val_loss: 0.6440 - val_mae: 0.6051 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.5369 - mae: 0.5728 - val_loss: 0.6252 - val_mae: 0.6021 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.5494 - mae: 0.5775 - val_loss: 0.6855 - val_mae: 0.6179 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.5147 - mae: 0.5565 - val_loss: 0.6237 - val_mae: 0.5985 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.5435 - mae: 0.5751 - val_loss: 0.6292 - val_mae: 0.5980 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - loss: 0.5310 - mae: 0.5756 - val_loss: 0.6259 - val_mae: 0.5915 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - loss: 0.5023 - mae: 0.5518 - val_loss: 0.6519 - val_mae: 0.6019 - learning_rate: 5.0000e-04\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n",
      "Epoch 1/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - loss: 0.7121 - mae: 0.6598 - val_loss: 0.6873 - val_mae: 0.6584 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.5586 - mae: 0.5739 - val_loss: 0.6544 - val_mae: 0.6441 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.5761 - mae: 0.5862 - val_loss: 0.6661 - val_mae: 0.6509 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 0.5610 - mae: 0.5883 - val_loss: 0.6437 - val_mae: 0.6387 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 0.6101 - mae: 0.6041 - val_loss: 0.6638 - val_mae: 0.6472 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 0.5294 - mae: 0.5661 - val_loss: 0.6458 - val_mae: 0.6438 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 0.5507 - mae: 0.5856 - val_loss: 0.6135 - val_mae: 0.6337 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - loss: 0.5515 - mae: 0.5810 - val_loss: 0.6132 - val_mae: 0.6334 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.5262 - mae: 0.5567 - val_loss: 0.6166 - val_mae: 0.6323 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 0.5005 - mae: 0.5520 - val_loss: 0.6011 - val_mae: 0.6287 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 0.5244 - mae: 0.5738 - val_loss: 0.6139 - val_mae: 0.6338 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 0.5011 - mae: 0.5534 - val_loss: 0.5856 - val_mae: 0.6214 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 0.5345 - mae: 0.5617 - val_loss: 0.5926 - val_mae: 0.6228 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - loss: 0.4712 - mae: 0.5326 - val_loss: 0.5884 - val_mae: 0.6185 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.4303 - mae: 0.5124 - val_loss: 0.5726 - val_mae: 0.6108 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.4541 - mae: 0.5193 - val_loss: 0.5657 - val_mae: 0.6003 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.3754 - mae: 0.4826 - val_loss: 0.5564 - val_mae: 0.5942 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 0.3588 - mae: 0.4611 - val_loss: 0.5457 - val_mae: 0.5790 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.3312 - mae: 0.4447 - val_loss: 0.5308 - val_mae: 0.5637 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 0.2955 - mae: 0.4254 - val_loss: 0.4695 - val_mae: 0.5339 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - loss: 0.3180 - mae: 0.4341 - val_loss: 0.4607 - val_mae: 0.5350 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 0.2612 - mae: 0.3923 - val_loss: 0.4874 - val_mae: 0.5351 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 0.2586 - mae: 0.3994 - val_loss: 0.4635 - val_mae: 0.5362 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.2464 - mae: 0.3805 - val_loss: 0.4527 - val_mae: 0.5203 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 0.2859 - mae: 0.4023 - val_loss: 0.4470 - val_mae: 0.5088 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 0.2208 - mae: 0.3595 - val_loss: 0.4863 - val_mae: 0.5444 - learning_rate: 0.0010\n",
      "Epoch 27/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - loss: 0.2479 - mae: 0.3794 - val_loss: 0.4273 - val_mae: 0.5077 - learning_rate: 0.0010\n",
      "Epoch 28/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - loss: 0.2275 - mae: 0.3673 - val_loss: 0.4478 - val_mae: 0.5224 - learning_rate: 0.0010\n",
      "Epoch 29/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.2205 - mae: 0.3672 - val_loss: 0.4825 - val_mae: 0.5385 - learning_rate: 0.0010\n",
      "Epoch 30/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 0.2274 - mae: 0.3684 - val_loss: 0.4527 - val_mae: 0.5325 - learning_rate: 0.0010\n",
      "Epoch 31/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - loss: 0.2121 - mae: 0.3550 - val_loss: 0.4680 - val_mae: 0.5271 - learning_rate: 0.0010\n",
      "Epoch 32/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - loss: 0.2128 - mae: 0.3612 - val_loss: 0.4694 - val_mae: 0.5264 - learning_rate: 0.0010\n",
      "Epoch 33/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.1799 - mae: 0.3318 - val_loss: 0.4617 - val_mae: 0.5219 - learning_rate: 5.0000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - loss: 0.1848 - mae: 0.3338 - val_loss: 0.4821 - val_mae: 0.5375 - learning_rate: 5.0000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - loss: 0.1898 - mae: 0.3411 - val_loss: 0.4809 - val_mae: 0.5356 - learning_rate: 5.0000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - loss: 0.1859 - mae: 0.3326 - val_loss: 0.4765 - val_mae: 0.5455 - learning_rate: 5.0000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 0.1770 - mae: 0.3228 - val_loss: 0.4686 - val_mae: 0.5290 - learning_rate: 5.0000e-04\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step\n",
      "========== XOM ==========\n",
      "Epoch 1/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 192ms/step - loss: 1.1532 - mae: 0.8541 - val_loss: 1.6348 - val_mae: 0.9743 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.7534 - mae: 0.6758 - val_loss: 1.4487 - val_mae: 0.8869 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.7366 - mae: 0.6578 - val_loss: 1.4233 - val_mae: 0.8823 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.5817 - mae: 0.5862 - val_loss: 1.4589 - val_mae: 0.9089 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.5271 - mae: 0.5520 - val_loss: 1.4711 - val_mae: 0.9180 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.5320 - mae: 0.5560 - val_loss: 1.4651 - val_mae: 0.9178 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.4734 - mae: 0.5272 - val_loss: 1.5367 - val_mae: 0.9550 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.5349 - mae: 0.5585 - val_loss: 1.5209 - val_mae: 0.9512 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.5370 - mae: 0.5652 - val_loss: 1.4351 - val_mae: 0.9129 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.5672 - mae: 0.5815 - val_loss: 1.4278 - val_mae: 0.9116 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.4963 - mae: 0.5388 - val_loss: 1.5773 - val_mae: 0.9835 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.5052 - mae: 0.5424 - val_loss: 1.6634 - val_mae: 1.0219 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.5074 - mae: 0.5447 - val_loss: 1.6314 - val_mae: 1.0097 - learning_rate: 5.0000e-04\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Epoch 1/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 114ms/step - loss: 1.1941 - mae: 0.8390 - val_loss: 0.4543 - val_mae: 0.5576 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 0.7168 - mae: 0.6399 - val_loss: 0.4585 - val_mae: 0.5633 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 0.6174 - mae: 0.5929 - val_loss: 0.4217 - val_mae: 0.5309 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.6292 - mae: 0.6072 - val_loss: 0.4287 - val_mae: 0.5270 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.6501 - mae: 0.6194 - val_loss: 0.4229 - val_mae: 0.5206 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.6090 - mae: 0.5951 - val_loss: 0.4012 - val_mae: 0.5086 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 0.6033 - mae: 0.5941 - val_loss: 0.4013 - val_mae: 0.5072 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.5914 - mae: 0.5879 - val_loss: 0.3861 - val_mae: 0.4863 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.5773 - mae: 0.5738 - val_loss: 0.3936 - val_mae: 0.4980 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.6062 - mae: 0.6016 - val_loss: 0.4087 - val_mae: 0.5131 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.5856 - mae: 0.5754 - val_loss: 0.4083 - val_mae: 0.5148 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.5109 - mae: 0.5442 - val_loss: 0.4210 - val_mae: 0.5264 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.5304 - mae: 0.5608 - val_loss: 0.4056 - val_mae: 0.5151 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.5417 - mae: 0.5578 - val_loss: 0.3959 - val_mae: 0.4952 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.5405 - mae: 0.5606 - val_loss: 0.4047 - val_mae: 0.5037 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.5267 - mae: 0.5565 - val_loss: 0.3964 - val_mae: 0.4959 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.5275 - mae: 0.5444 - val_loss: 0.4257 - val_mae: 0.5307 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.5417 - mae: 0.5672 - val_loss: 0.4367 - val_mae: 0.5378 - learning_rate: 5.0000e-04\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Epoch 1/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 109ms/step - loss: 0.7887 - mae: 0.6598 - val_loss: 0.3935 - val_mae: 0.5362 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.6595 - mae: 0.6365 - val_loss: 0.3522 - val_mae: 0.4825 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.6375 - mae: 0.6191 - val_loss: 0.3611 - val_mae: 0.5069 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - loss: 0.6616 - mae: 0.6195 - val_loss: 0.3530 - val_mae: 0.5003 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - loss: 0.6322 - mae: 0.6143 - val_loss: 0.3480 - val_mae: 0.4987 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.5991 - mae: 0.5942 - val_loss: 0.3369 - val_mae: 0.4793 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - loss: 0.6082 - mae: 0.6034 - val_loss: 0.3450 - val_mae: 0.4949 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - loss: 0.6563 - mae: 0.6286 - val_loss: 0.3333 - val_mae: 0.4740 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - loss: 0.5582 - mae: 0.5778 - val_loss: 0.3568 - val_mae: 0.4915 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - loss: 0.6623 - mae: 0.6327 - val_loss: 0.3273 - val_mae: 0.4705 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - loss: 0.5873 - mae: 0.5966 - val_loss: 0.3322 - val_mae: 0.4665 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - loss: 0.5734 - mae: 0.5729 - val_loss: 0.3504 - val_mae: 0.4831 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - loss: 0.6026 - mae: 0.5979 - val_loss: 0.3325 - val_mae: 0.4664 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - loss: 0.5261 - mae: 0.5665 - val_loss: 0.3250 - val_mae: 0.4649 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - loss: 0.5702 - mae: 0.5859 - val_loss: 0.3356 - val_mae: 0.4813 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.5163 - mae: 0.5648 - val_loss: 0.3089 - val_mae: 0.4546 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.4290 - mae: 0.5107 - val_loss: 0.2865 - val_mae: 0.4487 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.4601 - mae: 0.5355 - val_loss: 0.2694 - val_mae: 0.4209 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - loss: 0.4222 - mae: 0.5155 - val_loss: 0.2812 - val_mae: 0.4365 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - loss: 0.3833 - mae: 0.4817 - val_loss: 0.2918 - val_mae: 0.4449 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - loss: 0.3600 - mae: 0.4723 - val_loss: 0.2830 - val_mae: 0.4295 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 0.3020 - mae: 0.4372 - val_loss: 0.2570 - val_mae: 0.3904 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - loss: 0.2532 - mae: 0.4141 - val_loss: 0.3145 - val_mae: 0.4445 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - loss: 0.2671 - mae: 0.4102 - val_loss: 0.3170 - val_mae: 0.4460 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - loss: 0.2197 - mae: 0.3654 - val_loss: 0.3494 - val_mae: 0.4713 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - loss: 0.2267 - mae: 0.3824 - val_loss: 0.3073 - val_mae: 0.4357 - learning_rate: 0.0010\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.2259 - mae: 0.3740 - val_loss: 0.3384 - val_mae: 0.4604 - learning_rate: 0.0010\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - loss: 0.2292 - mae: 0.3721 - val_loss: 0.3177 - val_mae: 0.4410 - learning_rate: 5.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - loss: 0.2169 - mae: 0.3698 - val_loss: 0.2720 - val_mae: 0.4032 - learning_rate: 5.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - loss: 0.1974 - mae: 0.3614 - val_loss: 0.3274 - val_mae: 0.4480 - learning_rate: 5.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - loss: 0.2083 - mae: 0.3594 - val_loss: 0.3009 - val_mae: 0.4242 - learning_rate: 5.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - loss: 0.1927 - mae: 0.3484 - val_loss: 0.2868 - val_mae: 0.4100 - learning_rate: 5.0000e-04\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step\n",
      "Epoch 1/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 88ms/step - loss: 0.9867 - mae: 0.7608 - val_loss: 0.6008 - val_mae: 0.5769 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - loss: 0.6469 - mae: 0.6314 - val_loss: 0.5854 - val_mae: 0.5924 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.6941 - mae: 0.6442 - val_loss: 0.5793 - val_mae: 0.5904 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.6723 - mae: 0.6382 - val_loss: 0.5789 - val_mae: 0.5946 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - loss: 0.6780 - mae: 0.6369 - val_loss: 0.5986 - val_mae: 0.6161 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.6271 - mae: 0.6182 - val_loss: 0.5923 - val_mae: 0.5881 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.6302 - mae: 0.6032 - val_loss: 0.5987 - val_mae: 0.6117 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.6205 - mae: 0.6207 - val_loss: 0.5862 - val_mae: 0.6003 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.6087 - mae: 0.6059 - val_loss: 0.6040 - val_mae: 0.6127 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.6137 - mae: 0.6046 - val_loss: 0.6201 - val_mae: 0.6265 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.6277 - mae: 0.6185 - val_loss: 0.6176 - val_mae: 0.6278 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 0.6056 - mae: 0.5993 - val_loss: 0.6297 - val_mae: 0.6361 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.5794 - mae: 0.5864 - val_loss: 0.6126 - val_mae: 0.6210 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.5601 - mae: 0.5878 - val_loss: 0.6265 - val_mae: 0.6317 - learning_rate: 5.0000e-04\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for ticker in TICKERS:\n",
    "    print(f\"========== {ticker} ==========\")\n",
    "    df = pd.read_csv(f\"../data/processed/integrated/{ticker}_integrated.csv\")\n",
    "    fold_size = len(df) // N_FOLDS\n",
    "\n",
    "    # Store fold-level results for Diebold-Mariano\n",
    "    all_preds = { 'Technical': [], 'Fundamental': [], 'Sentiment': [], 'TFMS': [], 'y_true': [] }\n",
    "\n",
    "    for fold in range(N_FOLDS):\n",
    "        split = fold_size * (fold + 1)\n",
    "        if split + LOOKBACK - 1 > len(df):\n",
    "            break\n",
    "        train_df = df.iloc[:split + LOOKBACK - 1].copy()\n",
    "        test_df = df.iloc[split:split + fold_size + LOOKBACK - 1].copy()\n",
    "\n",
    "        # --- 1. Technical only model (LSTM)\n",
    "        # Prepare rolling window\n",
    "        X_train_tech, y_train = create_rolling_sequences(train_df, TECHNICAL_FEATURES, TARGET_COL, LOOKBACK)\n",
    "        X_test_tech, y_test = create_rolling_sequences(test_df, TECHNICAL_FEATURES, TARGET_COL, LOOKBACK)\n",
    "        # Scale\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        scaler = StandardScaler()\n",
    "        X_train_tech_flat = X_train_tech.reshape(-1, len(TECHNICAL_FEATURES))\n",
    "        X_train_tech_scaled_flat = scaler.fit_transform(X_train_tech_flat)\n",
    "        X_train_tech_scaled = X_train_tech_scaled_flat.reshape(X_train_tech.shape)\n",
    "        X_test_tech_flat = X_test_tech.reshape(-1, len(TECHNICAL_FEATURES))\n",
    "        X_test_tech_scaled_flat = scaler.transform(X_test_tech_flat)\n",
    "        X_test_tech_scaled = X_test_tech_scaled_flat.reshape(X_test_tech.shape)\n",
    "\n",
    "        # Train LSTM\n",
    "        lstm_model = train_technical_model(X_train_tech_scaled, y_train, X_test_tech_scaled, y_test)\n",
    "        tech_pred = lstm_model.predict(X_test_tech_scaled).flatten()\n",
    "\n",
    "        # --- 2. Fundamental only model (XGBoost, or your own)\n",
    "        X_train_fund = train_df[FUNDAMENTAL_FEATURES].iloc[LOOKBACK-1:LOOKBACK-1+len(y_train)].to_numpy()\n",
    "        X_test_fund = test_df[FUNDAMENTAL_FEATURES].iloc[LOOKBACK-1:LOOKBACK-1+len(y_test)].to_numpy()\n",
    "        xgb_model = train_fundamental_model(X_train_fund, y_train)\n",
    "        fund_pred = xgb_model.predict(X_test_fund)\n",
    "\n",
    "        # --- 3. Sentiment only model (LinearRegressor as default)\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "        X_train_sent = train_df[SENTIMENT_FEATURES].iloc[LOOKBACK-1:LOOKBACK-1+len(y_train)].to_numpy()\n",
    "        X_test_sent = test_df[SENTIMENT_FEATURES].iloc[LOOKBACK-1:LOOKBACK-1+len(y_test)].to_numpy()\n",
    "        sent_model = LinearRegression()\n",
    "        sent_model.fit(X_train_sent, y_train)\n",
    "        sent_pred = sent_model.predict(X_test_sent)\n",
    "\n",
    "        # --- 4. Full TFMS Ensemble (Stack predictions)\n",
    "        tech_train_pred = lstm_model.predict(X_train_tech_scaled).flatten()\n",
    "        fund_train_pred = xgb_model.predict(X_train_fund)\n",
    "        sent_train_pred = sent_model.predict(X_train_sent)\n",
    "        stack_X_train = np.column_stack([tech_train_pred, fund_train_pred, sent_train_pred])\n",
    "        meta_model = RandomForestRegressor(n_estimators=50, random_state=42)\n",
    "        meta_model.fit(stack_X_train, y_train)\n",
    "\n",
    "        stack_X_test = np.column_stack([tech_pred, fund_pred, sent_pred])\n",
    "        tfms_pred = meta_model.predict(stack_X_test)\n",
    "\n",
    "        # --- Metrics for each\n",
    "        for model_name, pred in zip(['Technical', 'Fundamental', 'Sentiment', 'TFMS'],\n",
    "                                    [tech_pred, fund_pred, sent_pred, tfms_pred]):\n",
    "            acc = direction_accuracy(y_test, pred)\n",
    "            err = rmse(y_test, pred)\n",
    "            # Sharpe: use true Close price for equity curves\n",
    "            close_aligned = test_df['Close'].iloc[LOOKBACK-1:LOOKBACK-1+len(y_test)].to_numpy()\n",
    "            returns = np.log(close_aligned[1:] / close_aligned[:-1])\n",
    "            side = np.where(pred > 0, 1, -1)\n",
    "            strat_returns = returns * side[:-1]\n",
    "            sharpe = sharpe_ratio(strat_returns)\n",
    "            results.append({\n",
    "                \"Ticker\": ticker, \"Fold\": fold+1, \"Model\": model_name, \n",
    "                \"RMSE\": err, \"Accuracy\": acc, \"Sharpe\": sharpe\n",
    "            })\n",
    "            all_preds[model_name].append(pred)\n",
    "        all_preds['y_true'].append(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2cfa5a5-a7df-4035-a5df-56ee11cb5e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diebold-Mariano Test Results (TFMS vs variant):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Model_1</th>\n",
       "      <th>Model_2</th>\n",
       "      <th>DM_statistic</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>TFMS</td>\n",
       "      <td>Technical</td>\n",
       "      <td>-30.880219</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>TFMS</td>\n",
       "      <td>Fundamental</td>\n",
       "      <td>-1.238002</td>\n",
       "      <td>0.215715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>TFMS</td>\n",
       "      <td>Sentiment</td>\n",
       "      <td>-0.903460</td>\n",
       "      <td>0.366282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JPM</td>\n",
       "      <td>TFMS</td>\n",
       "      <td>Technical</td>\n",
       "      <td>-30.880219</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JPM</td>\n",
       "      <td>TFMS</td>\n",
       "      <td>Fundamental</td>\n",
       "      <td>-1.238002</td>\n",
       "      <td>0.215715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>JPM</td>\n",
       "      <td>TFMS</td>\n",
       "      <td>Sentiment</td>\n",
       "      <td>-0.903460</td>\n",
       "      <td>0.366282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>TFMS</td>\n",
       "      <td>Technical</td>\n",
       "      <td>-30.880219</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>TFMS</td>\n",
       "      <td>Fundamental</td>\n",
       "      <td>-1.238002</td>\n",
       "      <td>0.215715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>TFMS</td>\n",
       "      <td>Sentiment</td>\n",
       "      <td>-0.903460</td>\n",
       "      <td>0.366282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PFE</td>\n",
       "      <td>TFMS</td>\n",
       "      <td>Technical</td>\n",
       "      <td>-30.880219</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PFE</td>\n",
       "      <td>TFMS</td>\n",
       "      <td>Fundamental</td>\n",
       "      <td>-1.238002</td>\n",
       "      <td>0.215715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PFE</td>\n",
       "      <td>TFMS</td>\n",
       "      <td>Sentiment</td>\n",
       "      <td>-0.903460</td>\n",
       "      <td>0.366282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>XOM</td>\n",
       "      <td>TFMS</td>\n",
       "      <td>Technical</td>\n",
       "      <td>-30.880219</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XOM</td>\n",
       "      <td>TFMS</td>\n",
       "      <td>Fundamental</td>\n",
       "      <td>-1.238002</td>\n",
       "      <td>0.215715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XOM</td>\n",
       "      <td>TFMS</td>\n",
       "      <td>Sentiment</td>\n",
       "      <td>-0.903460</td>\n",
       "      <td>0.366282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ticker Model_1      Model_2  DM_statistic   p_value\n",
       "0    AAPL    TFMS    Technical    -30.880219  0.000000\n",
       "1    AAPL    TFMS  Fundamental     -1.238002  0.215715\n",
       "2    AAPL    TFMS    Sentiment     -0.903460  0.366282\n",
       "3     JPM    TFMS    Technical    -30.880219  0.000000\n",
       "4     JPM    TFMS  Fundamental     -1.238002  0.215715\n",
       "5     JPM    TFMS    Sentiment     -0.903460  0.366282\n",
       "6    AMZN    TFMS    Technical    -30.880219  0.000000\n",
       "7    AMZN    TFMS  Fundamental     -1.238002  0.215715\n",
       "8    AMZN    TFMS    Sentiment     -0.903460  0.366282\n",
       "9     PFE    TFMS    Technical    -30.880219  0.000000\n",
       "10    PFE    TFMS  Fundamental     -1.238002  0.215715\n",
       "11    PFE    TFMS    Sentiment     -0.903460  0.366282\n",
       "12    XOM    TFMS    Technical    -30.880219  0.000000\n",
       "13    XOM    TFMS  Fundamental     -1.238002  0.215715\n",
       "14    XOM    TFMS    Sentiment     -0.903460  0.366282"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare per-fold prediction error streams, TFMS vs each ablation variant\n",
    "dm_results = []\n",
    "\n",
    "for ticker in TICKERS:\n",
    "    subset = [r for r in results if r['Ticker'] == ticker]\n",
    "    # You should also save per-fold y_true and y_pred above if you want per-fold DM test\n",
    "    # We'll use the last set from ablation loop's all_preds\n",
    "    y_true_full = np.concatenate(all_preds['y_true'])\n",
    "    preds_dict = {name: np.concatenate(all_preds[name]) for name in ['Technical', 'Fundamental', 'Sentiment', 'TFMS']}\n",
    "    for compare_model in ['Technical', 'Fundamental', 'Sentiment']:\n",
    "        e1 = y_true_full - preds_dict['TFMS']\n",
    "        e2 = y_true_full - preds_dict[compare_model]\n",
    "        dm_stat, pval = diebold_mariano_test(e1, e2)\n",
    "        dm_results.append({\n",
    "            \"Ticker\": ticker,\n",
    "            \"Model_1\": \"TFMS\",\n",
    "            \"Model_2\": compare_model,\n",
    "            \"DM_statistic\": dm_stat,\n",
    "            \"p_value\": pval\n",
    "        })\n",
    "        \n",
    "# Format DM test summary\n",
    "dm_df = pd.DataFrame(dm_results)\n",
    "print(\"Diebold-Mariano Test Results (TFMS vs variant):\")\n",
    "display(dm_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b6320ec-f1ef-45c5-a589-827ccf7decf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Fold</th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sharpe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>1</td>\n",
       "      <td>Technical</td>\n",
       "      <td>0.819558</td>\n",
       "      <td>0.792952</td>\n",
       "      <td>3.708372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>1</td>\n",
       "      <td>Fundamental</td>\n",
       "      <td>0.045951</td>\n",
       "      <td>0.453744</td>\n",
       "      <td>-0.583469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>1</td>\n",
       "      <td>Sentiment</td>\n",
       "      <td>0.046369</td>\n",
       "      <td>0.453744</td>\n",
       "      <td>-0.583469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>1</td>\n",
       "      <td>TFMS</td>\n",
       "      <td>0.039548</td>\n",
       "      <td>0.735683</td>\n",
       "      <td>1.224180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2</td>\n",
       "      <td>Technical</td>\n",
       "      <td>0.514156</td>\n",
       "      <td>0.797357</td>\n",
       "      <td>4.716066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ticker  Fold        Model      RMSE  Accuracy    Sharpe\n",
       "0   AAPL     1    Technical  0.819558  0.792952  3.708372\n",
       "1   AAPL     1  Fundamental  0.045951  0.453744 -0.583469\n",
       "2   AAPL     1    Sentiment  0.046369  0.453744 -0.583469\n",
       "3   AAPL     1         TFMS  0.039548  0.735683  1.224180\n",
       "4   AAPL     2    Technical  0.514156  0.797357  4.716066"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('../data/results/metrics/ablation_metrics.csv', index=False)\n",
    "dm_df.to_csv('../data/results/metrics/ablation_dm_test.csv', index=False)\n",
    "results_df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
