{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "868e0fb0-54a9-4fe2-bafa-1261a3f7b073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Cell 1: Install Libraries (Run Once) ---\n",
    "# !pip install yfinance alpha_vantage newsapi pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a88fd2f3-b5a7-45bb-a8ac-7f36fd31b2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping newsapi as it is not installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: newsapi-python in c:\\users\\kiit\\appdata\\roaming\\python\\python312\\site-packages (0.2.7)\n",
      "Requirement already satisfied: requests<3.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from newsapi-python) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0->newsapi-python) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0->newsapi-python) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0->newsapi-python) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0->newsapi-python) (2024.12.14)\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall newsapi -y\n",
    "!pip install newsapi-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07c5c9b0-049f-4234-aeaa-7fe7d4b5c4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 2: Import Libraries ---\n",
    "import yfinance as yf\n",
    "from alpha_vantage.fundamentaldata import FundamentalData\n",
    "from newsapi.newsapi_client import NewsApiClient\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Create data directories if they don't exist\n",
    "os.makedirs(\"../data/raw\", exist_ok=True)\n",
    "os.makedirs(\"../data/processed\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d2a3427-5e31-4517-b4fd-81736241cb7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading AAPL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['AAPL']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Warning: No data for AAPL\n",
      "Downloading JPM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['JPM']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Warning: No data for JPM\n",
      "Downloading AMZN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['AMZN']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Warning: No data for AMZN\n",
      "Downloading PFE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['PFE']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Warning: No data for PFE\n",
      "Downloading XOM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['XOM']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Warning: No data for XOM\n",
      "\n",
      "Failed to download all stocks.\n"
     ]
    }
   ],
   "source": [
    "# import yfinance as yf\n",
    "# import pandas as pd\n",
    "# import time\n",
    "\n",
    "# tickers = [\"AAPL\", \"JPM\", \"AMZN\", \"PFE\", \"XOM\"]\n",
    "# start_date = \"2020-01-01\"\n",
    "# end_date = \"2023-12-31\"\n",
    "\n",
    "# # Initialize empty DataFrame\n",
    "# all_prices = pd.DataFrame()\n",
    "\n",
    "# for ticker in tickers:\n",
    "#     try:\n",
    "#         print(f\"Downloading {ticker}...\")\n",
    "#         data = yf.download(ticker, start=start_date, end=end_date, progress=False)\n",
    "#         if not data.empty:\n",
    "#             all_prices[ticker] = data['Adj Close']\n",
    "#             print(f\"✅ Success: {ticker} ({len(data)} rows)\")\n",
    "#         else:\n",
    "#             print(f\"⚠️ Warning: No data for {ticker}\")\n",
    "#         time.sleep(2)  # Add 2-second delay between requests\n",
    "#     except Exception as e:\n",
    "#         print(f\"❌ Failed {ticker}: {e}\")\n",
    "\n",
    "# # Save results\n",
    "# if not all_prices.empty:\n",
    "#     all_prices.to_csv(\"../data/raw/stock_prices.csv\")\n",
    "#     print(f\"\\nSaved data for {len(all_prices.columns)} stocks:\\n{all_prices.head()}\")\n",
    "# else:\n",
    "#     print(\"\\nFailed to download all stocks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a7d541e-1f77-4b28-95bd-3bd2bc5b4b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading fundamental data...\n",
      "Saved AAPL fundamentals to ../data/raw/AAPL_fundamentals.csv\n",
      "Saved JPM fundamentals to ../data/raw/JPM_fundamentals.csv\n",
      "Saved AMZN fundamentals to ../data/raw/AMZN_fundamentals.csv\n",
      "Saved PFE fundamentals to ../data/raw/PFE_fundamentals.csv\n",
      "Saved XOM fundamentals to ../data/raw/XOM_fundamentals.csv\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 4: Fetch Fundamental Data ---\n",
    "# Replace with your Alpha Vantage API key (free tier: https://www.alphavantage.co/)\n",
    "av_key = \"8M56YMGH1YBO0KYD\"\n",
    "\n",
    "print(\"Downloading fundamental data...\")\n",
    "fd = FundamentalData(key=av_key, output_format='pandas')\n",
    "\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        # Get annual balance sheet\n",
    "        balance_sheet, _ = fd.get_balance_sheet_annual(ticker)\n",
    "        balance_sheet.to_csv(f\"../data/raw/{ticker}_fundamentals.csv\")\n",
    "        print(f\"Saved {ticker} fundamentals to ../data/raw/{ticker}_fundamentals.csv\")\n",
    "        time.sleep(12)  # Rate limit (5 requests/minute)\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching {ticker}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b31b864e-db89-48a3-a9d1-a420d92e7d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 100 recent articles for AAPL (2025-06-24 to 2025-07-24)\n",
      "✅ Saved 100 recent articles for JPM (2025-06-24 to 2025-07-24)\n",
      "✅ Saved 100 recent articles for AMZN (2025-06-24 to 2025-07-24)\n",
      "✅ Saved 33 recent articles for PFE (2025-06-24 to 2025-07-24)\n",
      "✅ Saved 100 recent articles for XOM (2025-06-24 to 2025-07-24)\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 5: Fetch News Sentiment Data ---\n",
    "# Replace with your NewsAPI key (free tier: https://newsapi.org/)\n",
    "# --- Updated Cell 5: Fetch News Sentiment (Valid Date Range) ---\n",
    "from newsapi.newsapi_client import NewsApiClient\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# --- Configure Dates ---\n",
    "end_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "start_date = (datetime.now() - timedelta(days=30)).strftime(\"%Y-%m-%d\")  # Free tier limit\n",
    "\n",
    "# --- Fetch News ---\n",
    "newsapi = NewsApiClient(api_key=\"ffc2fe4dd7774f61914f971b2a1d77d6\")  # Replace with your key\n",
    "\n",
    "for ticker in [\"AAPL\", \"JPM\", \"AMZN\", \"PFE\", \"XOM\"]:\n",
    "    try:\n",
    "        articles = newsapi.get_everything(\n",
    "            q=ticker,\n",
    "            from_param=start_date,\n",
    "            to=end_date,\n",
    "            language=\"en\",\n",
    "            sort_by=\"relevancy\"\n",
    "        )\n",
    "        news_df = pd.DataFrame(articles['articles'])\n",
    "        if not news_df.empty:\n",
    "            news_df.to_csv(f\"../data/raw/{ticker}_news_recent.csv\")\n",
    "            print(f\"✅ Saved {len(news_df)} recent articles for {ticker} ({start_date} to {end_date})\")\n",
    "        else:\n",
    "            print(f\"⚠️ No recent articles found for {ticker}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed {ticker}: {str(e)[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114e102d-e3b0-4be8-88e5-be80c66beae8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
